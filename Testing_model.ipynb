{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N    10117\n",
      "Y     4985\n",
      "Name: SUSPECT_ARRESTED_FLAG, dtype: int64\n",
      "STOP_WAS_INITIATED                0\n",
      "OBSERVED_DURATION_MINUTES         0\n",
      "SUSPECTED_CRIME_DESCRIPTION       0\n",
      "STOP_DURATION_MINUTES             0\n",
      "SUSPECT_ARRESTED_FLAG             0\n",
      "FIREARM_FLAG                      0\n",
      "DEMEANOR_OF_PERSON_STOPPED     1907\n",
      "SUSPECT_RACE_DESCRIPTION        192\n",
      "SUSPECT_BODY_BUILD_TYPE         573\n",
      "dtype: int64\n",
      "new STOP_WAS_INITIATED                0\n",
      "OBSERVED_DURATION_MINUTES         0\n",
      "SUSPECTED_CRIME_DESCRIPTION       0\n",
      "STOP_DURATION_MINUTES             0\n",
      "SUSPECT_ARRESTED_FLAG             0\n",
      "FIREARM_FLAG                      0\n",
      "DEMEANOR_OF_PERSON_STOPPED     1907\n",
      "SUSPECT_RACE_DESCRIPTION          0\n",
      "SUSPECT_BODY_BUILD_TYPE           0\n",
      "dtype: int64\n",
      "300.0\n",
      "61.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# for ensemble method use\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "dummy_reg = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "# height removed\n",
    "Test_Target = [\"SUSPECT_ARRESTED_FLAG\", \"STOP_WAS_INITIATED\",\n",
    "                 \"OBSERVED_DURATION_MINUTES\", \"SUSPECTED_CRIME_DESCRIPTION\",\n",
    "                 \"STOP_DURATION_MINUTES\", \"FIREARM_FLAG\",\n",
    "                 \"SUSPECT_RACE_DESCRIPTION\",\n",
    "                 \"DEMEANOR_OF_PERSON_STOPPED\", \"SUSPECT_BODY_BUILD_TYPE\"]\n",
    "Test1 = pd.read_excel(\"sqf2022.xlsx\", usecols=Test_Target)\n",
    "\n",
    "#print('MAX1:', Test1[\"OBSERVED_DURATION_MINUTES\"].max())\n",
    "\n",
    "#MS = Test1[\"STOP_DURATION_MINUTES\"].values.reshape(-1, 1)\n",
    "#scaler2 = StandardScaler()\n",
    "#z_scores2 = scaler2.fit_transform(MS)\n",
    "\n",
    "#outliers2 = np.where(z_scores2 > 1.5)\n",
    "#Test1 = Test1.drop(outliers2[0], axis=0)\n",
    "#print('MAX2:', Test1[\"STOP_DURATION_MINUTES\"].max())\n",
    "\n",
    "\n",
    "\n",
    "Feature_test=[\"FIREARM_FLAG\", \"STOP_DURATION_MINUTES\", \"STOP_DURATION_MINUTES\"]\n",
    "#C_Feature_test=[\"STOP_WAS_INITIATED\",\"SUSPECTED_CRIME_DESCRIPTION\",\"SUSPECT_RACE_DESCRIPTION\",\"DEMEANOR_OF_PERSON_STOPPED\"]\n",
    "value_counts = Test1['SUSPECT_ARRESTED_FLAG'].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Test1['FIREARM_FLAG'] = Test1['FIREARM_FLAG'].replace('(null)', 'No')\n",
    "Test1.replace('(null)', np.nan, inplace=True)\n",
    "print(Test1.isna().sum())\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "Test1[\"SUSPECT_ARRESTED_FLAG\"] = lb.fit_transform(Test1[\"SUSPECT_ARRESTED_FLAG\"])\n",
    "Test1[\"FIREARM_FLAG\"] = lb.fit_transform(Test1[\"FIREARM_FLAG\"])\n",
    "\n",
    "Test1[\"SUSPECT_ARRESTED_FLAG\"].fillna(Test1[\"SUSPECT_ARRESTED_FLAG\"].median,inplace=True)\n",
    "Test1[\"FIREARM_FLAG\"].fillna(Test1[\"FIREARM_FLAG\"].median,inplace=True)\n",
    "\n",
    "mode_val = Test1[\"SUSPECT_RACE_DESCRIPTION\"].mode()[0]\n",
    "Test1[\"SUSPECT_RACE_DESCRIPTION\"].fillna(mode_val, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "Test1.to_csv('output.csv', index=False)\n",
    "#one Hot encoding\n",
    "OneHot_Encode_feature = [\"STOP_WAS_INITIATED\",\"SUSPECTED_CRIME_DESCRIPTION\",\"SUSPECT_RACE_DESCRIPTION\"]\n",
    "Label_En = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "Feature_Encoded = Label_En.fit_transform(Test1[OneHot_Encode_feature])\n",
    "Label_df = pd.DataFrame(Feature_Encoded.toarray(), columns=Label_En.get_feature_names_out(OneHot_Encode_feature))\n",
    "#Label_df.fillna(value=0, inplace=True)\n",
    "#Label_df.fillna(median)\n",
    "\n",
    "\n",
    "#label encoding\n",
    "LE=LabelEncoder()\n",
    "Test1['SUSPECT_BODY_BUILD_TYPE']=LE.fit_transform(Test1[\"SUSPECT_BODY_BUILD_TYPE\"])\n",
    "Test1['SUSPECT_BODY_BUILD_TYPE'].fillna(Test1['SUSPECT_BODY_BUILD_TYPE'].mean, inplace=True)\n",
    "#test is there still nan\n",
    "print(\"new\",Test1.isna().sum())\n",
    "\n",
    "#cat_feature=list(Label_df.columns)+['SUSPECT_BODY_BUILD_TYPE']\n",
    "#with everything, un comment the below code to include both Categorical data and numeric in RandomForest\n",
    "cat_feature=list(Label_df.columns)+['SUSPECT_BODY_BUILD_TYPE']+Feature_test\n",
    "\n",
    "\n",
    "Test1 = pd.concat([Test1, Label_df], axis=1)\n",
    "\n",
    "# drop the original categorical feature column\n",
    "Test1 = Test1.drop(columns=OneHot_Encode_feature)\n",
    "\n",
    "cols = ['OBSERVED_DURATION_MINUTES', 'STOP_DURATION_MINUTES']\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the features\n",
    "Test1[cols] = scaler.fit_transform(Test1[cols])\n",
    "\n",
    "# Define the threshold for outlier detection\n",
    "threshold = 3\n",
    "\n",
    "# Calculate the absolute z-score for each data point\n",
    "z = np.abs(Test1[cols].values)\n",
    "\n",
    "# Identify the rows that contain outliers\n",
    "outliers = np.where(z > threshold)[0]\n",
    "\n",
    "# Remove the rows that contain outliers\n",
    "Test1 = Test1.drop(outliers, axis=0)\n",
    "\n",
    "# Inverse transform the standardized data to obtain the original values\n",
    "Test1[cols] = scaler.inverse_transform(Test1[cols])\n",
    "print(Test1['OBSERVED_DURATION_MINUTES'].max())\n",
    "print(Test1['STOP_DURATION_MINUTES'].max())\n",
    "\n",
    "train_data,test_data=train_test_split(Test1,test_size=0.2,random_state=42)\n",
    "\n",
    "# TODO: add linear regression to models: LinearRegression()\n",
    "models = [RandomForestClassifier(random_state=42),RandomForestClassifier(random_state=42),\n",
    "            LogisticRegression(random_state=0,max_iter=1000),DecisionTreeClassifier(random_state=42)\n",
    "         ]\n",
    "\n",
    "\n",
    "\n",
    "# extract the categorical features and target variable from the training and testing data\n",
    "#Random Forest\n",
    "X_train = train_data[cat_feature] # training features_for Random forest\n",
    "y_train = train_data['SUSPECT_ARRESTED_FLAG'] # training target variable for random forest\n",
    "\n",
    "X_test = test_data[cat_feature] # testing features\n",
    "y_test = test_data['SUSPECT_ARRESTED_FLAG'] # testing target variable\n",
    "\n",
    "#Linear regression\n",
    "X_train_linear=train_data[Feature_test] \n",
    "y_train_linear=train_data[\"SUSPECT_ARRESTED_FLAG\"]\n",
    "\n",
    "X_test_linear=test_data[Feature_test]\n",
    "y_test_linear=test_data['SUSPECT_ARRESTED_FLAG']\n",
    "\n",
    "#count Nan in dataset\n",
    "#print(Test1.isna().sum())\n",
    "# LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "# models \n",
    "Test1.to_csv('output.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "new OBSERVED_DURATION_MINUTES                                                     0\n",
      "STOP_DURATION_MINUTES                                                         0\n",
      "SUSPECT_ARRESTED_FLAG                                                         0\n",
      "FIREARM_FLAG                                                                  0\n",
      "DEMEANOR_OF_PERSON_STOPPED                                                 1879\n",
      "SUSPECT_BODY_BUILD_TYPE                                                       0\n",
      "STOP_WAS_INITIATED_Based on C/W on Scene                                      0\n",
      "STOP_WAS_INITIATED_Based on Radio Run                                         0\n",
      "STOP_WAS_INITIATED_Based on Self Initiated                                    0\n",
      "SUSPECTED_CRIME_DESCRIPTION_ASSAULT                                           0\n",
      "SUSPECTED_CRIME_DESCRIPTION_AUTO STRIPPIG                                     0\n",
      "SUSPECTED_CRIME_DESCRIPTION_BURGLARY                                          0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CPSP                                              0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CPW                                               0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL MISCHIEF                                 0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL POSSESSION OF CONTROLLED SUBSTANCE       0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL POSSESSION OF FORGED INSTRUMENT          0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL POSSESSION OF MARIHUANA                  0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL SALE OF CONTROLLED SUBSTANCE             0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL SALE OF MARIHUANA                        0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL TRESPASS                                 0\n",
      "SUSPECTED_CRIME_DESCRIPTION_FORCIBLE TOUCHING                                 0\n",
      "SUSPECTED_CRIME_DESCRIPTION_GRAND LARCENY                                     0\n",
      "SUSPECTED_CRIME_DESCRIPTION_GRAND LARCENY AUTO                                0\n",
      "SUSPECTED_CRIME_DESCRIPTION_MAKING GRAFFITI                                   0\n",
      "SUSPECTED_CRIME_DESCRIPTION_MENACING                                          0\n",
      "SUSPECTED_CRIME_DESCRIPTION_MURDER                                            0\n",
      "SUSPECTED_CRIME_DESCRIPTION_OTHER                                             0\n",
      "SUSPECTED_CRIME_DESCRIPTION_PETIT LARCENY                                     0\n",
      "SUSPECTED_CRIME_DESCRIPTION_RAPE                                              0\n",
      "SUSPECTED_CRIME_DESCRIPTION_RECKLESS ENDANGERMENT                             0\n",
      "SUSPECTED_CRIME_DESCRIPTION_ROBBERY                                           0\n",
      "SUSPECTED_CRIME_DESCRIPTION_TERRORISM                                         0\n",
      "SUSPECTED_CRIME_DESCRIPTION_THEFT OF SERVICES                                 0\n",
      "SUSPECTED_CRIME_DESCRIPTION_UNAUTHORIZED USE OF A VEHICLE                     0\n",
      "SUSPECT_RACE_DESCRIPTION_AMERICAN INDIAN/ALASKAN NATIVE                       0\n",
      "SUSPECT_RACE_DESCRIPTION_ASIAN / PACIFIC ISLANDER                             0\n",
      "SUSPECT_RACE_DESCRIPTION_BLACK                                                0\n",
      "SUSPECT_RACE_DESCRIPTION_BLACK HISPANIC                                       0\n",
      "SUSPECT_RACE_DESCRIPTION_MIDDLE EASTERN/SOUTHWEST ASIAN                       0\n",
      "SUSPECT_RACE_DESCRIPTION_WHITE                                                0\n",
      "SUSPECT_RACE_DESCRIPTION_WHITE HISPANIC                                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(np.any(np.isnan(X_train)))\n",
    "print(np.any(np.isinf(X_train)))\n",
    "print(np.any(np.isnan(X_train)))\n",
    "print(np.any(np.isinf(X_train)))\n",
    "print(\"new\",Test1.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.7434276206322795\n",
      "Accuracy: 0.7571975370277917\n"
     ]
    }
   ],
   "source": [
    "Model_N=MultinomialNB()\n",
    "Model_N.fit(X_train,y_train)\n",
    "N_prediction=Model_N.predict(X_test)\n",
    "train_N_prediction=Model_N.predict(X_train)\n",
    "N_train_accuracy=accuracy_score(y_train,train_N_prediction)\n",
    "N_accuracy=accuracy_score(y_test,N_prediction)\n",
    "\n",
    "print('Train_Accuracy:', N_accuracy)\n",
    "print('Accuracy:', N_train_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.8707771675819604\n",
      "Accuracy: 0.7420965058236273\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_R = RandomForestClassifier(random_state=42)\n",
    "#model_R.fit(train_data[Feature_test], train_data[\"SUSPECT_ARRESTED_FLAG\"])\n",
    "\n",
    "#with only caterogical data but transform to numeric/ with both\n",
    "\n",
    "model_R.fit(X_train,y_train)\n",
    "Prediction=model_R.predict(X_test)\n",
    "\n",
    "train_Prediction =model_R.predict(X_train)\n",
    "\n",
    "\n",
    "train_accuracy=accuracy_score(y_train,train_Prediction)\n",
    "\n",
    "accuracy = accuracy_score(y_test, Prediction)\n",
    "\n",
    "\n",
    "print('Train_Accuracy:', train_accuracy)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RMSE: 0.402452932211559\n",
      "Training RMSE: 0.39692006686466\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing and training data, and calculate RMSE\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "\n",
    "print('Testing RMSE:', test_rmse)\n",
    "print('Training RMSE:', train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7480865224625624\n",
      "Train Accuract: 0.7627725079048094\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "log_predict=logreg.predict(X_test)\n",
    "log_score=accuracy_score(y_test,log_predict)\n",
    "\n",
    "train_log_predict=logreg.predict(X_train)\n",
    "train_log_score=accuracy_score(y_train,train_log_predict)\n",
    "\n",
    "print(\"Accuracy:\",log_score)\n",
    "print(\"Train Accuract:\",train_log_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score:  0.7311148086522462\n",
      "Train_Decision Tree score:  0.8707771675819604\n"
     ]
    }
   ],
   "source": [
    "Dec_model=DecisionTreeClassifier(random_state=42)\n",
    "Dec_model.fit(X_train,y_train)\n",
    "Dec_predict=Dec_model.predict(X_test)\n",
    "Train_Dec_predict=Dec_model.predict(X_train)\n",
    "Dec_accuracy=accuracy_score(y_test,Dec_predict)\n",
    "Train_Dec_accuracy=accuracy_score(y_train,Train_Dec_predict)\n",
    "print(\"Decision Tree score: \",Dec_accuracy)\n",
    "print(\"Train_Decision Tree score: \",Train_Dec_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error 0.46963995436032246\n",
      "TestError: 0.4737658361546264\n"
     ]
    }
   ],
   "source": [
    "dummy_reg=DummyRegressor(strategy=\"mean\")\n",
    "dummy_reg.fit(X_train,y_train)\n",
    "y_train_predict=dummy_reg.predict(X_train)\n",
    "\n",
    "trainerror=mean_squared_error(y_train,y_train_predict,squared=False)\n",
    "\n",
    "\n",
    "y_pred=dummy_reg.predict(X_test)\n",
    "testerror=mean_squared_error(y_test,y_pred,squared=False)\n",
    "\n",
    "print(\"Training error\",trainerror)\n",
    "print(\"TestError:\", testerror)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.7474609178903521 \n",
      " \n",
      "\n",
      "RandomForestClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.7474609178903521 \n",
      " \n",
      "\n",
      "LogisticRegression(max_iter=1000, random_state=0) \n",
      "\n",
      "Cross-Validation Accuracy: 0.7611085837655788 \n",
      " \n",
      "\n",
      "DecisionTreeClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.7388913816132497 \n",
      " \n",
      "\n",
      "0.7384359400998336\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model, '\\n')\n",
    "    score = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=5).mean()\n",
    "    print('Cross-Validation Accuracy:', score, '\\n', '\\n')\n",
    "\n",
    "estimators=[(\"logreg\", logreg), (\"rf\", model_R), (\"Dc\", Dec_model),(\"Linear\",model)]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators)\n",
    "ensemble.fit(X_train, y_train)\n",
    "#test our model on the test data\n",
    "print(ensemble.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
