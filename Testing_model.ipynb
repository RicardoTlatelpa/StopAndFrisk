{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N    10117\n",
      "Y     4985\n",
      "Name: SUSPECT_ARRESTED_FLAG, dtype: int64\n",
      "STOP_WAS_INITIATED                0\n",
      "OBSERVED_DURATION_MINUTES         0\n",
      "SUSPECTED_CRIME_DESCRIPTION       0\n",
      "STOP_DURATION_MINUTES             0\n",
      "SUSPECT_ARRESTED_FLAG             0\n",
      "FRISKED_FLAG                      0\n",
      "SEARCHED_FLAG                     0\n",
      "FIREARM_FLAG                      0\n",
      "DEMEANOR_OF_PERSON_STOPPED     1907\n",
      "SUSPECT_RACE_DESCRIPTION        192\n",
      "SUSPECT_BODY_BUILD_TYPE         573\n",
      "STOP_LOCATION_BORO_NAME           0\n",
      "dtype: int64\n",
      "new STOP_WAS_INITIATED                0\n",
      "OBSERVED_DURATION_MINUTES         0\n",
      "SUSPECTED_CRIME_DESCRIPTION       0\n",
      "STOP_DURATION_MINUTES             0\n",
      "SUSPECT_ARRESTED_FLAG             0\n",
      "FRISKED_FLAG                      0\n",
      "SEARCHED_FLAG                     0\n",
      "FIREARM_FLAG                      0\n",
      "DEMEANOR_OF_PERSON_STOPPED     1907\n",
      "SUSPECT_RACE_DESCRIPTION          0\n",
      "SUSPECT_BODY_BUILD_TYPE           0\n",
      "STOP_LOCATION_BORO_NAME           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# for ensemble method use\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "dummy_reg = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "# height removed\n",
    "Test_Target = [\"SUSPECT_ARRESTED_FLAG\", \"STOP_WAS_INITIATED\",\n",
    "                 \"OBSERVED_DURATION_MINUTES\", \"SUSPECTED_CRIME_DESCRIPTION\",\n",
    "                 \"STOP_DURATION_MINUTES\", \"FIREARM_FLAG\",\n",
    "                 \"SUSPECT_RACE_DESCRIPTION\",\n",
    "                 \"DEMEANOR_OF_PERSON_STOPPED\", \"SUSPECT_BODY_BUILD_TYPE\",\"FRISKED_FLAG\",\"SEARCHED_FLAG\",\"STOP_LOCATION_BORO_NAME\"]\n",
    "Test1 = pd.read_excel(\"sqf2022.xlsx\", usecols=Test_Target)\n",
    "\n",
    "#print('MAX1:', Test1[\"OBSERVED_DURATION_MINUTES\"].max())\n",
    "\n",
    "#MS = Test1[\"STOP_DURATION_MINUTES\"].values.reshape(-1, 1)\n",
    "#scaler2 = StandardScaler()\n",
    "#z_scores2 = scaler2.fit_transform(MS)\n",
    "\n",
    "#outliers2 = np.where(z_scores2 > 1.5)\n",
    "#Test1 = Test1.drop(outliers2[0], axis=0)\n",
    "#print('MAX2:', Test1[\"STOP_DURATION_MINUTES\"].max())\n",
    "\n",
    "\n",
    "\n",
    "Feature_test=[\"FIREARM_FLAG\",\"FRISKED_FLAG\",\"SEARCHED_FLAG\"]\n",
    "#C_Feature_test=[\"STOP_WAS_INITIATED\",\"SUSPECTED_CRIME_DESCRIPTION\",\"SUSPECT_RACE_DESCRIPTION\",\"DEMEANOR_OF_PERSON_STOPPED\"]\n",
    "value_counts = Test1['SUSPECT_ARRESTED_FLAG'].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Test1['FIREARM_FLAG'] = Test1['FIREARM_FLAG'].replace('(null)', 'No')\n",
    "Test1.replace('(null)', np.nan, inplace=True)\n",
    "print(Test1.isna().sum())\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "Test1[\"SUSPECT_ARRESTED_FLAG\"] = lb.fit_transform(Test1[\"SUSPECT_ARRESTED_FLAG\"])\n",
    "Test1[\"FIREARM_FLAG\"] = lb.fit_transform(Test1[\"FIREARM_FLAG\"])\n",
    "Test1[\"FRISKED_FLAG\"] = lb.fit_transform(Test1[\"FRISKED_FLAG\"])\n",
    "Test1[\"SEARCHED_FLAG\"] = lb.fit_transform(Test1[\"SEARCHED_FLAG\"])\n",
    "\n",
    "\n",
    "Test1[\"SUSPECT_ARRESTED_FLAG\"].fillna(Test1[\"SUSPECT_ARRESTED_FLAG\"].median,inplace=True)\n",
    "Test1[\"FIREARM_FLAG\"].fillna(Test1[\"FIREARM_FLAG\"].median,inplace=True)\n",
    "Test1[\"FRISKED_FLAG\"].fillna(Test1[\"FRISKED_FLAG\"].median,inplace=True)\n",
    "Test1[\"SEARCHED_FLAG\"].fillna(Test1[\"SEARCHED_FLAG\"].median,inplace=True)\n",
    "\n",
    "mode_val = Test1[\"SUSPECT_RACE_DESCRIPTION\"].mode()[0]\n",
    "Test1[\"SUSPECT_RACE_DESCRIPTION\"].fillna(mode_val, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "Test1.to_csv('output.csv', index=False)\n",
    "#one Hot encoding\n",
    "OneHot_Encode_feature = [\"STOP_WAS_INITIATED\",\"SUSPECTED_CRIME_DESCRIPTION\"]\n",
    "Label_En = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "Feature_Encoded = Label_En.fit_transform(Test1[OneHot_Encode_feature])\n",
    "Label_df = pd.DataFrame(Feature_Encoded.toarray(), columns=Label_En.get_feature_names_out(OneHot_Encode_feature))\n",
    "#Label_df.fillna(value=0, inplace=True)\n",
    "#Label_df.fillna(median)\n",
    "\n",
    "\n",
    "#label encoding\n",
    "LE=LabelEncoder()\n",
    "Test1['SUSPECT_BODY_BUILD_TYPE']=LE.fit_transform(Test1[\"SUSPECT_BODY_BUILD_TYPE\"])\n",
    "Test1['SUSPECT_BODY_BUILD_TYPE'].fillna(Test1['SUSPECT_BODY_BUILD_TYPE'].mean, inplace=True)\n",
    "#test is there still nan\n",
    "print(\"new\",Test1.isna().sum())\n",
    "\n",
    "#cat_feature=list(Label_df.columns)+['SUSPECT_BODY_BUILD_TYPE']\n",
    "#with everything, un comment the below code to include both Categorical data and numeric in RandomForest\n",
    "#cat_feature=list(Label_df.columns)+['SUSPECT_BODY_BUILD_TYPE']+Feature_test\n",
    "cat_feature=list(Label_df.columns)+Feature_test\n",
    "\n",
    "\n",
    "Test1 = pd.concat([Test1, Label_df], axis=1)\n",
    "\n",
    "# drop the original categorical feature column\n",
    "Test1 = Test1.drop(columns=OneHot_Encode_feature)\n",
    "\n",
    "#cols = ['OBSERVED_DURATION_MINUTES', 'STOP_DURATION_MINUTES']\n",
    "\n",
    "# Create a StandardScaler object\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "# Standardize the features\n",
    "#Test1[cols] = scaler.fit_transform(Test1[cols])\n",
    "\n",
    "# Define the threshold for outlier detection\n",
    "#threshold = 3\n",
    "\n",
    "# Calculate the absolute z-score for each data point\n",
    "#z = np.abs(Test1[cols].values)\n",
    "\n",
    "# Identify the rows that contain outliers\n",
    "#outliers = np.where(z > threshold)[0]\n",
    "\n",
    "# Remove the rows that contain outliers\n",
    "#Test1 = Test1.drop(outliers, axis=0)\n",
    "\n",
    "# Inverse transform the standardized data to obtain the original values\n",
    "#Test1[cols] = scaler.inverse_transform(Test1[cols])\n",
    "#print(Test1['OBSERVED_DURATION_MINUTES'].max())\n",
    "#print(Test1['STOP_DURATION_MINUTES'].max())\n",
    "\n",
    "train_data,test_data=train_test_split(Test1,test_size=0.2,random_state=42)\n",
    "\n",
    "# TODO: add linear regression to models: LinearRegression()\n",
    "models = [RandomForestClassifier(random_state=42),RandomForestClassifier(random_state=42),\n",
    "            LogisticRegression(random_state=0,max_iter=1000),DecisionTreeClassifier(random_state=42),MultinomialNB()\n",
    "         ]\n",
    "\n",
    "\n",
    "\n",
    "# extract the categorical features and target variable from the training and testing data\n",
    "#Random Forest\n",
    "X_train = train_data[cat_feature] # training features_for Random forest\n",
    "y_train = train_data['SUSPECT_ARRESTED_FLAG'] # training target variable for random forest\n",
    "\n",
    "X_test = test_data[cat_feature] # testing features\n",
    "y_test = test_data['SUSPECT_ARRESTED_FLAG'] # testing target variable\n",
    "\n",
    "#Linear regression\n",
    "X_train_linear=train_data[Feature_test] \n",
    "y_train_linear=train_data[\"SUSPECT_ARRESTED_FLAG\"]\n",
    "\n",
    "X_test_linear=test_data[Feature_test]\n",
    "y_test_linear=test_data['SUSPECT_ARRESTED_FLAG']\n",
    "\n",
    "#count Nan in dataset\n",
    "#print(Test1.isna().sum())\n",
    "# LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "# models \n",
    "Test1.to_csv('output.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "new OBSERVED_DURATION_MINUTES                                                     0\n",
      "STOP_DURATION_MINUTES                                                         0\n",
      "SUSPECT_ARRESTED_FLAG                                                         0\n",
      "FRISKED_FLAG                                                                  0\n",
      "SEARCHED_FLAG                                                                 0\n",
      "FIREARM_FLAG                                                                  0\n",
      "DEMEANOR_OF_PERSON_STOPPED                                                 1907\n",
      "SUSPECT_RACE_DESCRIPTION                                                      0\n",
      "SUSPECT_BODY_BUILD_TYPE                                                       0\n",
      "STOP_LOCATION_BORO_NAME                                                       0\n",
      "STOP_WAS_INITIATED_Based on C/W on Scene                                      0\n",
      "STOP_WAS_INITIATED_Based on Radio Run                                         0\n",
      "STOP_WAS_INITIATED_Based on Self Initiated                                    0\n",
      "SUSPECTED_CRIME_DESCRIPTION_ASSAULT                                           0\n",
      "SUSPECTED_CRIME_DESCRIPTION_AUTO STRIPPIG                                     0\n",
      "SUSPECTED_CRIME_DESCRIPTION_BURGLARY                                          0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CPSP                                              0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CPW                                               0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL MISCHIEF                                 0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL POSSESSION OF CONTROLLED SUBSTANCE       0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL POSSESSION OF FORGED INSTRUMENT          0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL POSSESSION OF MARIHUANA                  0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL SALE OF CONTROLLED SUBSTANCE             0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL SALE OF MARIHUANA                        0\n",
      "SUSPECTED_CRIME_DESCRIPTION_CRIMINAL TRESPASS                                 0\n",
      "SUSPECTED_CRIME_DESCRIPTION_FORCIBLE TOUCHING                                 0\n",
      "SUSPECTED_CRIME_DESCRIPTION_GRAND LARCENY                                     0\n",
      "SUSPECTED_CRIME_DESCRIPTION_GRAND LARCENY AUTO                                0\n",
      "SUSPECTED_CRIME_DESCRIPTION_MAKING GRAFFITI                                   0\n",
      "SUSPECTED_CRIME_DESCRIPTION_MENACING                                          0\n",
      "SUSPECTED_CRIME_DESCRIPTION_MURDER                                            0\n",
      "SUSPECTED_CRIME_DESCRIPTION_OTHER                                             0\n",
      "SUSPECTED_CRIME_DESCRIPTION_PETIT LARCENY                                     0\n",
      "SUSPECTED_CRIME_DESCRIPTION_RAPE                                              0\n",
      "SUSPECTED_CRIME_DESCRIPTION_RECKLESS ENDANGERMENT                             0\n",
      "SUSPECTED_CRIME_DESCRIPTION_ROBBERY                                           0\n",
      "SUSPECTED_CRIME_DESCRIPTION_TERRORISM                                         0\n",
      "SUSPECTED_CRIME_DESCRIPTION_THEFT OF SERVICES                                 0\n",
      "SUSPECTED_CRIME_DESCRIPTION_UNAUTHORIZED USE OF A VEHICLE                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(np.any(np.isnan(X_train)))\n",
    "print(np.any(np.isinf(X_train)))\n",
    "print(np.any(np.isnan(X_train)))\n",
    "print(np.any(np.isinf(X_train)))\n",
    "print(\"new\",Test1.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.8391261171797418\n",
      "Accuracy: 0.8370168032447645\n"
     ]
    }
   ],
   "source": [
    "Model_N=MultinomialNB()\n",
    "Model_N.fit(X_train,y_train)\n",
    "N_prediction=Model_N.predict(X_test)\n",
    "train_N_prediction=Model_N.predict(X_train)\n",
    "N_train_accuracy=accuracy_score(y_train,train_N_prediction)\n",
    "N_accuracy=accuracy_score(y_test,N_prediction)\n",
    "\n",
    "print('Train_Accuracy:', N_accuracy)\n",
    "print('Accuracy:', N_train_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.8673950831884778\n",
      "Accuracy: 0.8679245283018868\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_R = RandomForestClassifier(random_state=42)\n",
    "#model_R.fit(train_data[Feature_test], train_data[\"SUSPECT_ARRESTED_FLAG\"])\n",
    "\n",
    "#with only caterogical data but transform to numeric/ with both\n",
    "\n",
    "model_R.fit(X_train,y_train)\n",
    "Prediction=model_R.predict(X_test)\n",
    "\n",
    "train_Prediction =model_R.predict(X_train)\n",
    "\n",
    "\n",
    "train_accuracy=accuracy_score(y_train,train_Prediction)\n",
    "\n",
    "accuracy = accuracy_score(y_test, Prediction)\n",
    "\n",
    "\n",
    "print('Train_Accuracy:', train_accuracy)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RMSE: 0.34058471641017063\n",
      "Training RMSE: 0.345491521615495\n"
     ]
    }
   ],
   "source": [
    "model_L = LinearRegression()\n",
    "model_L.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing and training data, and calculate RMSE\n",
    "y_test_pred = model_L.predict(X_test)\n",
    "y_train_pred = model_L.predict(X_train)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "\n",
    "print('Testing RMSE:', test_rmse)\n",
    "print('Training RMSE:', train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8659384309831182\n",
      "Train Accuract: 0.8611042132273818\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "log_predict=logreg.predict(X_test)\n",
    "log_score=accuracy_score(y_test,log_predict)\n",
    "\n",
    "train_log_predict=logreg.predict(X_train)\n",
    "train_log_score=accuracy_score(y_train,train_log_predict)\n",
    "\n",
    "print(\"Accuracy:\",log_score)\n",
    "print(\"Train Accuract:\",train_log_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score:  0.8652763985435287\n",
      "Train_Decision Tree score:  0.8673950831884778\n"
     ]
    }
   ],
   "source": [
    "Dec_model=DecisionTreeClassifier(random_state=42)\n",
    "Dec_model.fit(X_train,y_train)\n",
    "Dec_predict=Dec_model.predict(X_test)\n",
    "Train_Dec_predict=Dec_model.predict(X_train)\n",
    "Dec_accuracy=accuracy_score(y_test,Dec_predict)\n",
    "Train_Dec_accuracy=accuracy_score(y_train,Train_Dec_predict)\n",
    "print(\"Decision Tree score: \",Dec_accuracy)\n",
    "print(\"Train_Decision Tree score: \",Train_Dec_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error 0.47084552628064064\n",
      "TestError: 0.46784965294918474\n"
     ]
    }
   ],
   "source": [
    "dummy_reg=DummyRegressor(strategy=\"mean\")\n",
    "dummy_reg.fit(X_train,y_train)\n",
    "y_train_predict=dummy_reg.predict(X_train)\n",
    "\n",
    "trainerror=mean_squared_error(y_train,y_train_predict,squared=False)\n",
    "\n",
    "\n",
    "y_pred=dummy_reg.predict(X_test)\n",
    "testerror=mean_squared_error(y_test,y_pred,squared=False)\n",
    "\n",
    "print(\"Training error\",trainerror)\n",
    "print(\"TestError:\", testerror)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.8620978746023613 \n",
      " \n",
      "\n",
      "RandomForestClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.8620978746023613 \n",
      " \n",
      "\n",
      "LogisticRegression(max_iter=1000, random_state=0) \n",
      "\n",
      "Cross-Validation Accuracy: 0.8614354859480446 \n",
      " \n",
      "\n",
      "DecisionTreeClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.860938762956651 \n",
      " \n",
      "\n",
      "MultinomialNB() \n",
      "\n",
      "Cross-Validation Accuracy: 0.8336231426402934 \n",
      " \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The estimator LinearRegression should be a classifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l0/dqqn7htx52gbmyf1bnbpby0m0000gn/T/ipykernel_4696/3181252616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#create our voting classifier, inputting our models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mensemble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#test our model on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;34m\"\"\"Get common fit operations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_validate_estimators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"drop\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    263\u001b[0m                     \"The estimator {} should be a {}.\".format(\n\u001b[1;32m    264\u001b[0m                         \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The estimator LinearRegression should be a classifier."
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model, '\\n')\n",
    "    score = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=5).mean()\n",
    "    print('Cross-Validation Accuracy:', score, '\\n', '\\n')\n",
    "\n",
    "estimators=[(\"logreg\", logreg), (\"rf\", model_R), (\"Dc\", Dec_model),(\"Linear\",model_L),(\"Naive\",Model_N)]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators)\n",
    "ensemble.fit(X_train, y_train)\n",
    "#test our model on the test data\n",
    "print(ensemble.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
