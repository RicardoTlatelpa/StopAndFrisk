{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N    10117\n",
      "Y     4985\n",
      "Name: SUSPECT_ARRESTED_FLAG, dtype: int64\n",
      "STOP_WAS_INITIATED                0\n",
      "OBSERVED_DURATION_MINUTES         0\n",
      "SUSPECTED_CRIME_DESCRIPTION       0\n",
      "STOP_DURATION_MINUTES             0\n",
      "SUSPECT_ARRESTED_FLAG             0\n",
      "FIREARM_FLAG                      0\n",
      "DEMEANOR_OF_PERSON_STOPPED     1907\n",
      "SUSPECT_RACE_DESCRIPTION        192\n",
      "SUSPECT_BODY_BUILD_TYPE         573\n",
      "dtype: int64\n",
      "new STOP_WAS_INITIATED                0\n",
      "OBSERVED_DURATION_MINUTES         0\n",
      "SUSPECTED_CRIME_DESCRIPTION       0\n",
      "STOP_DURATION_MINUTES             0\n",
      "SUSPECT_ARRESTED_FLAG             0\n",
      "FIREARM_FLAG                      0\n",
      "DEMEANOR_OF_PERSON_STOPPED     1907\n",
      "SUSPECT_RACE_DESCRIPTION          0\n",
      "SUSPECT_BODY_BUILD_TYPE           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# for ensemble method use\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "\n",
    "\n",
    "dummy_reg = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "# height removed\n",
    "Test_Target = [\"SUSPECT_ARRESTED_FLAG\", \"STOP_WAS_INITIATED\",\n",
    "                 \"OBSERVED_DURATION_MINUTES\", \"SUSPECTED_CRIME_DESCRIPTION\",\n",
    "                 \"STOP_DURATION_MINUTES\", \"FIREARM_FLAG\",\n",
    "                 \"SUSPECT_RACE_DESCRIPTION\",\n",
    "                 \"DEMEANOR_OF_PERSON_STOPPED\", \"SUSPECT_BODY_BUILD_TYPE\"]\n",
    "Test1 = pd.read_excel(\"sqf2022.xlsx\", usecols=Test_Target)\n",
    "\n",
    "\n",
    "data=Test1[\"OBSERVED_DURATION_MINUTES\"].values.reshape(-1, 1)\n",
    "n_bin=3\n",
    "strategy = 'uniform'\n",
    "discretizer = KBinsDiscretizer(n_bins=n_bin, encode='ordinal', strategy=strategy)\n",
    "\n",
    "discretized_data = discretizer.fit_transform(data)\n",
    "#print(discretized_data)\n",
    "\n",
    "data2=Test1[\"STOP_DURATION_MINUTES\"].values.reshape(-1, 1)\n",
    "discretizer2 = KBinsDiscretizer(n_bins=n_bin, encode='ordinal', strategy=strategy)\n",
    "\n",
    "discretized_data2 = discretizer2.fit_transform(data)\n",
    "#print(discretized_data2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Feature_test=[\"FIREARM_FLAG\", \"STOP_DURATION_MINUTES\", \"STOP_DURATION_MINUTES\"]\n",
    "#C_Feature_test=[\"STOP_WAS_INITIATED\",\"SUSPECTED_CRIME_DESCRIPTION\",\"SUSPECT_RACE_DESCRIPTION\",\"DEMEANOR_OF_PERSON_STOPPED\"]\n",
    "value_counts = Test1['SUSPECT_ARRESTED_FLAG'].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Test1['FIREARM_FLAG'] = Test1['FIREARM_FLAG'].replace('(null)', 'No')\n",
    "Test1.replace('(null)', np.nan, inplace=True)\n",
    "print(Test1.isna().sum())\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "Test1[\"SUSPECT_ARRESTED_FLAG\"] = lb.fit_transform(Test1[\"SUSPECT_ARRESTED_FLAG\"])\n",
    "Test1[\"FIREARM_FLAG\"] = lb.fit_transform(Test1[\"FIREARM_FLAG\"])\n",
    "\n",
    "Test1[\"SUSPECT_ARRESTED_FLAG\"].fillna(Test1[\"SUSPECT_ARRESTED_FLAG\"].median,inplace=True)\n",
    "Test1[\"FIREARM_FLAG\"].fillna(Test1[\"FIREARM_FLAG\"].median,inplace=True)\n",
    "\n",
    "mode_val = Test1[\"SUSPECT_RACE_DESCRIPTION\"].mode()[0]\n",
    "Test1[\"SUSPECT_RACE_DESCRIPTION\"].fillna(mode_val, inplace=True)\n",
    "Test1.to_csv('output.csv', index=False)\n",
    "#one Hot encoding\n",
    "OneHot_Encode_feature = [\"STOP_WAS_INITIATED\",\"SUSPECTED_CRIME_DESCRIPTION\",\"SUSPECT_RACE_DESCRIPTION\"]\n",
    "Label_En = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "Feature_Encoded = Label_En.fit_transform(Test1[OneHot_Encode_feature])\n",
    "Label_df = pd.DataFrame(Feature_Encoded.toarray(), columns=Label_En.get_feature_names_out(OneHot_Encode_feature))\n",
    "#Label_df.fillna(value=0, inplace=True)\n",
    "#Label_df.fillna(median)\n",
    "\n",
    "\n",
    "#label encoding\n",
    "LE=LabelEncoder()\n",
    "Test1['SUSPECT_BODY_BUILD_TYPE']=LE.fit_transform(Test1[\"SUSPECT_BODY_BUILD_TYPE\"])\n",
    "Test1['SUSPECT_BODY_BUILD_TYPE'].fillna(Test1['SUSPECT_BODY_BUILD_TYPE'].mean, inplace=True)\n",
    "#test is there still nan\n",
    "print(\"new\",Test1.isna().sum())\n",
    "\n",
    "#cat_feature=list(Label_df.columns)+['SUSPECT_BODY_BUILD_TYPE']\n",
    "#with everything, un comment the below code to include both Categorical data and numeric in RandomForest\n",
    "cat_feature=list(Label_df.columns)+['SUSPECT_BODY_BUILD_TYPE']+Feature_test\n",
    "\n",
    "\n",
    "Test1 = pd.concat([Test1, Label_df], axis=1)\n",
    "\n",
    "# drop the original categorical feature column\n",
    "Test1 = Test1.drop(columns=OneHot_Encode_feature)\n",
    "train_data,test_data=train_test_split(Test1,test_size=0.2,random_state=42)\n",
    "\n",
    "# TODO: add linear regression to models: LinearRegression()\n",
    "models = [RandomForestClassifier(random_state=42),RandomForestClassifier(random_state=42),\n",
    "            LogisticRegression(random_state=0,max_iter=1000),DecisionTreeClassifier(random_state=42)\n",
    "         ]\n",
    "\n",
    "\n",
    "\n",
    "# extract the categorical features and target variable from the training and testing data\n",
    "#Random Forest\n",
    "X_train = train_data[cat_feature] # training features_for Random forest\n",
    "y_train = train_data['SUSPECT_ARRESTED_FLAG'] # training target variable for random forest\n",
    "\n",
    "X_test = test_data[cat_feature] # testing features\n",
    "y_test = test_data['SUSPECT_ARRESTED_FLAG'] # testing target variable\n",
    "\n",
    "#Linear regression\n",
    "X_train_linear=train_data[Feature_test] \n",
    "y_train_linear=train_data[\"SUSPECT_ARRESTED_FLAG\"]\n",
    "\n",
    "X_test_linear=test_data[Feature_test]\n",
    "y_test_linear=test_data['SUSPECT_ARRESTED_FLAG']\n",
    "\n",
    "#count Nan in dataset\n",
    "#print(Test1.isna().sum())\n",
    "# LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "# models \n",
    "Test1.to_csv('output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = Test1.corr()\n",
    "binary_feature_correlations = corr_matrix['SUSPECT_ARRESTED_FLAG'][Label_df.columns]\n",
    "\n",
    "binary_feature_correlations.to_csv('correlation_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.751075802714333\n",
      "Accuracy: 0.7534144524459896\n"
     ]
    }
   ],
   "source": [
    "Model_N=MultinomialNB()\n",
    "Model_N.fit(X_train,y_train)\n",
    "N_prediction=Model_N.predict(X_test)\n",
    "train_N_prediction=Model_N.predict(X_train)\n",
    "N_train_accuracy=accuracy_score(y_train,train_N_prediction)\n",
    "N_accuracy=accuracy_score(y_test,N_prediction)\n",
    "\n",
    "print('Train_Accuracy:', N_accuracy)\n",
    "print('Accuracy:', N_train_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.8689678006787518\n",
      "Accuracy: 0.7527308838133069\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_R = RandomForestClassifier(random_state=42)\n",
    "#model_R.fit(train_data[Feature_test], train_data[\"SUSPECT_ARRESTED_FLAG\"])\n",
    "\n",
    "#with only caterogical data but transform to numeric/ with both\n",
    "\n",
    "model_R.fit(X_train,y_train)\n",
    "Prediction=model_R.predict(X_test)\n",
    "\n",
    "train_Prediction =model_R.predict(X_train)\n",
    "\n",
    "\n",
    "train_accuracy=accuracy_score(y_train,train_Prediction)\n",
    "\n",
    "accuracy = accuracy_score(y_test, Prediction)\n",
    "\n",
    "\n",
    "print('Train_Accuracy:', train_accuracy)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RMSE: 0.3931235078709149\n",
      "Training RMSE: 0.3992759806098063\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing and training data, and calculate RMSE\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "\n",
    "print('Testing RMSE:', test_rmse)\n",
    "print('Training RMSE:', train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7653095001655081\n",
      "Train Accuract: 0.7560632397980299\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "log_predict=logreg.predict(X_test)\n",
    "log_score=accuracy_score(y_test,log_predict)\n",
    "\n",
    "train_log_predict=logreg.predict(X_train)\n",
    "train_log_score=accuracy_score(y_train,train_log_predict)\n",
    "\n",
    "print(\"Accuracy:\",log_score)\n",
    "print(\"Train Accuract:\",train_log_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score:  0.7391592188017213\n",
      "Train_Decision Tree score:  0.8689678006787518\n"
     ]
    }
   ],
   "source": [
    "Dec_model=DecisionTreeClassifier(random_state=42)\n",
    "Dec_model.fit(X_train,y_train)\n",
    "Dec_predict=Dec_model.predict(X_test)\n",
    "Train_Dec_predict=Dec_model.predict(X_train)\n",
    "Dec_accuracy=accuracy_score(y_test,Dec_predict)\n",
    "Train_Dec_accuracy=accuracy_score(y_train,Train_Dec_predict)\n",
    "print(\"Decision Tree score: \",Dec_accuracy)\n",
    "print(\"Train_Decision Tree score: \",Train_Dec_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error 0.47084552628064064\n",
      "TestError: 0.46784965294918474\n"
     ]
    }
   ],
   "source": [
    "dummy_reg=DummyRegressor(strategy=\"mean\")\n",
    "dummy_reg.fit(X_train,y_train)\n",
    "y_train_predict=dummy_reg.predict(X_train)\n",
    "\n",
    "trainerror=mean_squared_error(y_train,y_train_predict,squared=False)\n",
    "\n",
    "\n",
    "y_pred=dummy_reg.predict(X_test)\n",
    "testerror=mean_squared_error(y_test,y_pred,squared=False)\n",
    "\n",
    "print(\"Training error\",trainerror)\n",
    "print(\"TestError:\", testerror)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.7377699901634942 \n",
      " \n",
      "\n",
      "RandomForestClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.7377699901634942 \n",
      " \n",
      "\n",
      "LogisticRegression(max_iter=1000, random_state=0) \n",
      "\n",
      "Cross-Validation Accuracy: 0.7554842629607609 \n",
      " \n",
      "\n",
      "DecisionTreeClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.729988807207227 \n",
      " \n",
      "\n",
      "0.7494207216153591\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model, '\\n')\n",
    "    score = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=5).mean()\n",
    "    print('Cross-Validation Accuracy:', score, '\\n', '\\n')\n",
    "\n",
    "estimators=[(\"logreg\", logreg), (\"rf\", model_R), (\"Dc\", Dec_model),(\"Linear\",model)]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators)\n",
    "ensemble.fit(X_train, y_train)\n",
    "#test our model on the test data\n",
    "print(ensemble.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
