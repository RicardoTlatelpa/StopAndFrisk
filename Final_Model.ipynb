{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# for ensemble method use\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "#TO DO-\n",
    "#One-R\n",
    "# sampling SOMTE\n",
    "\n",
    "\n",
    "# height removed\n",
    "Test_Target = [\"SUSPECT_ARRESTED_FLAG\", \"STOP_WAS_INITIATED\",\n",
    "                 \"OBSERVED_DURATION_MINUTES\", \"SUSPECTED_CRIME_DESCRIPTION\",\n",
    "                 \"STOP_DURATION_MINUTES\", \"FIREARM_FLAG\",\n",
    "                 \"SUSPECT_RACE_DESCRIPTION\",\n",
    "                 \"DEMEANOR_OF_PERSON_STOPPED\", \"SUSPECT_BODY_BUILD_TYPE\",\"FRISKED_FLAG\",\"SEARCHED_FLAG\",\"STOP_LOCATION_BORO_NAME\"]\n",
    "Test1 = pd.read_excel(\"sqf2022.xlsx\", usecols=Test_Target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_test=[\"FIREARM_FLAG\",\"FRISKED_FLAG\",\"SEARCHED_FLAG\"]\n",
    "\n",
    "Test1['FIREARM_FLAG'] = Test1['FIREARM_FLAG'].replace('(null)', 'No')\n",
    "Test1.replace('(null)', np.nan, inplace=True)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "Test1[\"SUSPECT_ARRESTED_FLAG\"] = lb.fit_transform(Test1[\"SUSPECT_ARRESTED_FLAG\"])\n",
    "Test1[\"FIREARM_FLAG\"] = lb.fit_transform(Test1[\"FIREARM_FLAG\"])\n",
    "Test1[\"FRISKED_FLAG\"] = lb.fit_transform(Test1[\"FRISKED_FLAG\"])\n",
    "Test1[\"SEARCHED_FLAG\"] = lb.fit_transform(Test1[\"SEARCHED_FLAG\"])\n",
    "\n",
    "\n",
    "Test1[\"SUSPECT_ARRESTED_FLAG\"].fillna(Test1[\"SUSPECT_ARRESTED_FLAG\"].median,inplace=True)\n",
    "Test1[\"FIREARM_FLAG\"].fillna(Test1[\"FIREARM_FLAG\"].median,inplace=True)\n",
    "Test1[\"FRISKED_FLAG\"].fillna(Test1[\"FRISKED_FLAG\"].median,inplace=True)\n",
    "Test1[\"SEARCHED_FLAG\"].fillna(Test1[\"SEARCHED_FLAG\"].median,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot-Encoding\n",
    "OneHot_Encode_feature = [\"STOP_WAS_INITIATED\",\"SUSPECTED_CRIME_DESCRIPTION\"]\n",
    "Label_En = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "Feature_Encoded = Label_En.fit_transform(Test1[OneHot_Encode_feature])\n",
    "Label_df = pd.DataFrame(Feature_Encoded.toarray(), columns=Label_En.get_feature_names_out(OneHot_Encode_feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding\n",
    "LE=LabelEncoder()\n",
    "Test1['SUSPECT_BODY_BUILD_TYPE']=LE.fit_transform(Test1[\"SUSPECT_BODY_BUILD_TYPE\"])\n",
    "Test1['SUSPECT_BODY_BUILD_TYPE'].fillna(Test1['SUSPECT_BODY_BUILD_TYPE'].mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       agitated  angry  annoyed  calm  compliant  cooperative  nervous  \\\n",
      "0             0      0        0     0          0            0        0   \n",
      "1             0      0        0     0          0            0        0   \n",
      "2             0      0        0     0          0            0        1   \n",
      "3             0      0        0     1          0            0        0   \n",
      "4             0      0        0     1          0            0        0   \n",
      "...         ...    ...      ...   ...        ...          ...      ...   \n",
      "15097         0      0        0     0          0            0        0   \n",
      "15098         0      0        0     1          0            0        0   \n",
      "15099         0      0        0     0          1            0        0   \n",
      "15100         0      0        1     0          0            0        0   \n",
      "15101         0      0        1     0          1            0        0   \n",
      "\n",
      "       neutral  normal  upset  \n",
      "0            0       0      0  \n",
      "1            1       0      0  \n",
      "2            0       0      0  \n",
      "3            0       0      0  \n",
      "4            0       0      0  \n",
      "...        ...     ...    ...  \n",
      "15097        1       0      0  \n",
      "15098        0       0      0  \n",
      "15099        0       0      0  \n",
      "15100        0       0      0  \n",
      "15101        0       0      0  \n",
      "\n",
      "[15102 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shion/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Find a way to limit, max featrue, \n",
    "\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "Test1['DEMEANOR_OF_PERSON_STOPPED'].fillna('neutral', inplace=True)\n",
    "texts=Test1['DEMEANOR_OF_PERSON_STOPPED'].tolist()\n",
    "stop_words = ['the', 'is', 'and', 'to', 'of']\n",
    "\n",
    "# # Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=10,stop_words=stop_words)\n",
    "\n",
    "# # Fit and transform the texts using the CountVectorizer\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# # Get the feature names\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# # Convert the vectorized data to a DataFrame\n",
    "vectorized_data = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "\n",
    "# # Print the vectorized data\n",
    "print(vectorized_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l0/dqqn7htx52gbmyf1bnbpby0m0000gn/T/ipykernel_7567/2298264181.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sqf2022.xlsx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DEMEANOR_OF_PERSON_STOPPED\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlpp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neutral'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         data = io.parse(\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m   1456\u001b[0m             \u001b[0mDataFrame\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mExcel\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \"\"\"\n\u001b[0;32m-> 1458\u001b[0;31m         return self._reader.parse(\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0msheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sheet_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sheet_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"close\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0;31m# pyxlsb opens two TemporaryFiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36mget_sheet_data\u001b[0;34m(self, sheet, convert_float)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mScalar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0mlast_row_with_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mrow_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mconverted_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_float\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mconverted_row\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconverted_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openpyxl/worksheet/_read_only.py\u001b[0m in \u001b[0;36m_cells_by_row\u001b[0;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[1;32m     77\u001b[0m                                  \u001b[0mdata_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                                  date_formats=self.parent._date_formats)\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_row\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_row\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openpyxl/worksheet/_reader.cpython-39-darwin.so\u001b[0m in \u001b[0;36mparse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36miterator\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m   1258\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m                 \u001b[0mpullparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m             \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpullparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_and_return_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpullparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mSyntaxError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;34m\"\"\"Feed encoded data to parser.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raiseerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_aafi60xe3m/croots/recipe/python-split_1661469468466/work/Modules/pyexpat.c\u001b[0m in \u001b[0;36mStartElement\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, tag, attr_list)\u001b[0m\n\u001b[1;32m   1648\u001b[0m         \u001b[0;31m# attribute name,value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m         \u001b[0mfixname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fixname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m         \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m         \u001b[0mattrib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36m_fixname\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fixname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m         \u001b[0;31m# expand qname, and convert name string to ascii, if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1631\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nlpp = pd.read_excel(\"sqf2022.xlsx\", usecols=[\"DEMEANOR_OF_PERSON_STOPPED\"])\n",
    "print(len(nlpp))\n",
    "nlp = nlpp.fillna(value='neutral')\n",
    "print(len(nlp))\n",
    "\n",
    "# Assuming df is your DataFrame and 'column_name' is the name of the column you want to check\n",
    "null_count = nlp['DEMEANOR_OF_PERSON_STOPPED'].isnull().sum()\n",
    "print(len(nlp))\n",
    "print(f\"Number of null values in 'DEMEANOR_OF_PERSON_STOPPED': {null_count}\")\n",
    "data = nlp['DEMEANOR_OF_PERSON_STOPPED'].tolist()\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "new_data = [analyzer.polarity_scores(element)['compound'] for element in data]\n",
    "new = [(pair, compound) for pair, compound in zip(data, new_data)]\n",
    "# Create DataFrame from list of tuples\n",
    "final_df = pd.DataFrame(new, columns=['DEMEANOR_OF_PERSON_STOPPED', 'COMPOUND_SENTIMENT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Test1 = pd.concat([Test1, Label_df,vectorized_data], axis=1)\n",
    "Test1 = pd.concat([Test1, Label_df], axis=1)\n",
    "#Test1=pd.concat([Test1,vectorized_data],axis=1)\n",
    "#Test1 = pd.concat([Test1, final_df], axis=1)\n",
    "\n",
    "#cat_feature=list(Label_df.columns)+Feature_test+list(vectorized_data.columns)\n",
    "c\n",
    "#cat_feature=list(Label_df.columns)+Feature_test+[\"COMPOUND_SENTIMENT\"]\n",
    "\n",
    "cat_feature=list(Label_df.columns)+Feature_test\n",
    "\n",
    "# drop the original categorical feature column\n",
    "Test1 = Test1.drop(columns=OneHot_Encode_feature)\n",
    "Test1= Test1.drop(columns=\"DEMEANOR_OF_PERSON_STOPPED\")\n",
    "\n",
    "Test1.to_csv('output.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data,test_data=train_test_split(Test1,test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "#classi\n",
    "X_train = train_data[cat_feature] # training features_for Random forest\n",
    "y_train = train_data['SUSPECT_ARRESTED_FLAG'] # training target variable for random forest\n",
    "\n",
    "X_test = test_data[cat_feature] # testing features\n",
    "y_test = test_data['SUSPECT_ARRESTED_FLAG'] # testing target variable\n",
    "\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.8371400198609732\n",
      "Accuracy: 0.8342024666832216\n"
     ]
    }
   ],
   "source": [
    "Model_N=MultinomialNB()\n",
    "Model_N.fit(X_train,y_train)\n",
    "N_prediction=Model_N.predict(X_test)\n",
    "train_N_prediction=Model_N.predict(X_train)\n",
    "N_train_accuracy=accuracy_score(y_train,train_N_prediction)\n",
    "N_accuracy=accuracy_score(y_test,N_prediction)\n",
    "\n",
    "print('Train_Accuracy:', N_accuracy)\n",
    "print('Accuracy:', N_train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.8056484578223708\n",
      "Accuracy: 0.8020523005627276\n"
     ]
    }
   ],
   "source": [
    "Model_N_Over = MultinomialNB()\n",
    "Model_N_Over.fit(X_train_oversampled, y_train_oversampled)\n",
    "N_prediction_Over = Model_N_Over.predict(X_test)\n",
    "train_N_prediction_Over = Model_N_Over.predict(X_train_oversampled)\n",
    "N_train_accuracy_Over = accuracy_score(y_train_oversampled, train_N_prediction_Over)\n",
    "N_accuracy_Over = accuracy_score(y_test, N_prediction_Over)\n",
    "\n",
    "print('Train_Accuracy:', N_train_accuracy_Over)\n",
    "print('Accuracy:', N_accuracy_Over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.884198327952984\n",
      "Accuracy: 0.8603111552466071\n"
     ]
    }
   ],
   "source": [
    "model_R = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "model_R.fit(X_train,y_train)\n",
    "Prediction=model_R.predict(X_test)\n",
    "\n",
    "train_Prediction =model_R.predict(X_train)\n",
    "\n",
    "\n",
    "train_accuracy=accuracy_score(y_train,train_Prediction)\n",
    "\n",
    "accuracy = accuracy_score(y_test, Prediction)\n",
    "\n",
    "\n",
    "print('Train_Accuracy:', train_accuracy)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.8678929765886287\n",
      "Accuracy: 0.8440913604766633\n"
     ]
    }
   ],
   "source": [
    "model_R_Over = RandomForestClassifier(random_state=42)\n",
    "model_R_Over.fit(X_train_oversampled,y_train_oversampled)\n",
    "Prediction_Over=model_R_Over.predict(X_test)\n",
    "\n",
    "train_Prediction_Over =model_R_Over.predict(X_train_oversampled)\n",
    "\n",
    "\n",
    "train_accuracy_Over=accuracy_score(y_train_oversampled,train_Prediction_Over)\n",
    "\n",
    "accuracy_Over = accuracy_score(y_test, Prediction_Over)\n",
    "\n",
    "\n",
    "print('Train_Accuracy:', train_accuracy_Over)\n",
    "print('Accuracy:', accuracy_Over)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RMSE: 0.3399601630395756\n",
      "Training RMSE: 0.34444442968522904\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing and training data, and calculate RMSE\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "\n",
    "print('Testing RMSE:', test_rmse)\n",
    "print('Training RMSE:', train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8652763985435287\n",
      "Train Accuract: 0.8628424799271583\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000,random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "log_predict=logreg.predict(X_test)\n",
    "log_score=accuracy_score(y_test,log_predict)\n",
    "\n",
    "train_log_predict=logreg.predict(X_train)\n",
    "train_log_score=accuracy_score(y_train,train_log_predict)\n",
    "\n",
    "print(\"Accuracy:\",log_score)\n",
    "print(\"Train Accuract:\",train_log_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.854683879510096\n",
      "Train Accuracy: 0.8387835996531648\n"
     ]
    }
   ],
   "source": [
    "logreg_Over = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_Over.fit(X_train_oversampled, y_train_oversampled)\n",
    "log_predict_Over = logreg_Over.predict(X_test)\n",
    "log_score_Over = accuracy_score(y_test, log_predict_Over)\n",
    "\n",
    "train_log_predict_Over = logreg_Over.predict(X_train_oversampled)\n",
    "train_log_score_Over = accuracy_score(y_train_oversampled, train_log_predict_Over)\n",
    "\n",
    "print(\"Accuracy:\", log_score_Over)\n",
    "print(\"Train Accuracy:\", train_log_score_Over)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score:  0.8579940417080437\n",
      "Train_Decision Tree score:  0.884198327952984\n"
     ]
    }
   ],
   "source": [
    "Dec_model=DecisionTreeClassifier(random_state=42)\n",
    "Dec_model.fit(X_train,y_train)\n",
    "Dec_predict=Dec_model.predict(X_test)\n",
    "Train_Dec_predict=Dec_model.predict(X_train)\n",
    "Dec_accuracy=accuracy_score(y_test,Dec_predict)\n",
    "Train_Dec_accuracy=accuracy_score(y_train,Train_Dec_predict)\n",
    "print(\"Decision Tree score: \",Dec_accuracy)\n",
    "print(\"Train_Decision Tree score: \",Train_Dec_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score on testing data:  0.8477325388944058\n",
      "Decision Tree score on training data (oversampled):  0.8678929765886287\n"
     ]
    }
   ],
   "source": [
    "Dec_model_Over = DecisionTreeClassifier(random_state=42)\n",
    "Dec_model_Over.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "Dec_predict_Over = Dec_model_Over.predict(X_test)\n",
    "\n",
    "# Make predictions on the training data (oversampled)\n",
    "Train_Dec_predict_Over = Dec_model_Over.predict(X_train_oversampled)\n",
    "\n",
    "# Calculate accuracy scores\n",
    "Dec_accuracy_Over = accuracy_score(y_test, Dec_predict_Over)\n",
    "Train_Dec_accuracy_Over = accuracy_score(y_train_oversampled, Train_Dec_predict_Over)\n",
    "\n",
    "print(\"Decision Tree score on testing data: \", Dec_accuracy_Over)\n",
    "print(\"Decision Tree score on training data (oversampled): \", Train_Dec_accuracy_Over)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.6765971532605097\n",
      "training_score : 0.6682393841569406\n"
     ]
    }
   ],
   "source": [
    "dummy_class = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_class.fit(X_train,y_train)\n",
    "y_predict=dummy_class.predict(X_test)\n",
    "y_train_predict=dummy_class.predict(X_train)\n",
    "Dummy_accuracy = accuracy_score(y_test, y_predict)\n",
    "Dummy_train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "print(\"Score: \",Dummy_accuracy)\n",
    "print(\"training_score :\", Dummy_train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.6765971532605097\n",
      "training_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "dummy_class_over = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_class_over.fit(X_train_oversampled,y_train_oversampled)\n",
    "y_predict_over=dummy_class_over.predict(X_test)\n",
    "y_train_predict_over=dummy_class_over.predict(X_train_oversampled)\n",
    "Dummy_accuracy_over = accuracy_score(y_test, y_predict_over)\n",
    "Dummy_train_accuracy_over = accuracy_score(y_train_oversampled, y_train_predict_over)\n",
    "print(\"Score: \",Dummy_accuracy_over)\n",
    "print(\"training_score:\", Dummy_train_accuracy_over)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7871565706719629\n"
     ]
    }
   ],
   "source": [
    "Dec_model_OneR=DecisionTreeClassifier(random_state=42,max_depth=1)\n",
    "Dec_model_OneR.fit(train_data[\"SEARCHED_FLAG\"].values.reshape(-1, 1), train_data[\"SUSPECT_ARRESTED_FLAG\"])\n",
    "predictions = Dec_model_OneR.predict(test_data[\"SEARCHED_FLAG\"].values.reshape(-1, 1))\n",
    "accuracy_OneR = accuracy_score(test_data[\"SUSPECT_ARRESTED_FLAG\"], predictions)\n",
    "print(\"Accuracy:\", accuracy_OneR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7871565706719629\n"
     ]
    }
   ],
   "source": [
    "Dec_model_OneR=DecisionTreeClassifier(random_state=42,max_depth=1)\n",
    "Dec_model_OneR.fit(X_train_oversampled[\"SEARCHED_FLAG\"].values.reshape(-1, 1), y_train_oversampled)\n",
    "predictions = Dec_model_OneR.predict(test_data[\"SEARCHED_FLAG\"].values.reshape(-1, 1))\n",
    "accuracy_OneR = accuracy_score(test_data[\"SUSPECT_ARRESTED_FLAG\"], predictions)\n",
    "print(\"Accuracy:\", accuracy_OneR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier 0.86329030122476\n"
     ]
    }
   ],
   "source": [
    "estimators=[(\"logreg\", logreg), (\"rf\", model_R), (\"Dc\", Dec_model),(\"Naive\",Model_N)]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators)\n",
    "ensemble.fit(X_train, y_train)\n",
    "#test our model on the test data\n",
    "print(\"Voting Classifier\",ensemble.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier 0.8593181065872227\n"
     ]
    }
   ],
   "source": [
    "estimators=[(\"logreg\", logreg), (\"rf\", model_R), (\"Dc\", Dec_model),(\"Naive\",Model_N)]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators)\n",
    "ensemble.fit(X_train_oversampled, y_train_oversampled)\n",
    "#test our model on the test data\n",
    "print(\"Voting Classifier\",ensemble.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient  0.8689175769612711\n",
      "Train Gradient  0.8657395910934526\n"
     ]
    }
   ],
   "source": [
    "G_Model=GradientBoostingClassifier(random_state=42) #Gradient Boosted Decision Trees\n",
    "G_Model.fit(X_train,y_train)\n",
    "G_predict=G_Model.predict(X_test)\n",
    "G_predict_train=G_Model.predict(X_train)\n",
    "G_accracy=accuracy_score(y_test,G_predict)\n",
    "G_accracy_train=accuracy_score(y_train,G_predict_train)\n",
    "print(\"Gradient \", G_accracy)\n",
    "print(\"Train Gradient \", G_accracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient  0.86329030122476\n",
      "Train Gradient  0.8431190387712126\n"
     ]
    }
   ],
   "source": [
    "G_Model=GradientBoostingClassifier(random_state=42) #Gradient Boosted Decision Trees\n",
    "G_Model.fit(X_train_oversampled,y_train_oversampled)\n",
    "G_predict=G_Model.predict(X_test)\n",
    "G_predict_train=G_Model.predict(X_train_oversampled)\n",
    "G_accracy=accuracy_score(y_test,G_predict)\n",
    "G_accracy_train=accuracy_score(y_train_oversampled,G_predict_train)\n",
    "print(\"Gradient \", G_accracy)\n",
    "print(\"Train Gradient \", G_accracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.8520828252965338 \n",
      " \n",
      "\n",
      "RandomForestClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.8520828252965338 \n",
      " \n",
      "\n",
      "LogisticRegression(max_iter=1000, random_state=0) \n",
      "\n",
      "Cross-Validation Accuracy: 0.8607731657930717 \n",
      " \n",
      "\n",
      "DecisionTreeClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.8487719437647788 \n",
      " \n",
      "\n",
      "MultinomialNB() \n",
      "\n",
      "Cross-Validation Accuracy: 0.8319677874985958 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [RandomForestClassifier(random_state=42),RandomForestClassifier(random_state=42),\n",
    "            LogisticRegression(random_state=0,max_iter=1000),DecisionTreeClassifier(random_state=42),MultinomialNB()\n",
    "         ]\n",
    "for model in models:\n",
    "    print(model, '\\n')\n",
    "    score = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=5).mean()\n",
    "    print('Cross-Validation Accuracy:', score, '\\n', '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
