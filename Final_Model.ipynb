{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# for ensemble method use\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "#TO DO-\n",
    "#One-R\n",
    "# sampling SOMTE\n",
    "\n",
    "\n",
    "# height removed\n",
    "Test_Target = [\"SUSPECT_ARRESTED_FLAG\", \"STOP_WAS_INITIATED\",\n",
    "                 \"OBSERVED_DURATION_MINUTES\", \"SUSPECTED_CRIME_DESCRIPTION\",\n",
    "                 \"STOP_DURATION_MINUTES\", \"FIREARM_FLAG\",\n",
    "                 \"SUSPECT_RACE_DESCRIPTION\",\n",
    "                 \"DEMEANOR_OF_PERSON_STOPPED\", \"SUSPECT_BODY_BUILD_TYPE\",\"FRISKED_FLAG\",\"SEARCHED_FLAG\",\"STOP_LOCATION_BORO_NAME\"]\n",
    "Test1 = pd.read_excel(\"sqf2022.xlsx\", usecols=Test_Target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlpp = pd.read_excel(\"sqf2022.xlsx\", usecols=[\"DEMEANOR_OF_PERSON_STOPPED\"])\n",
    "print(len(nlpp))\n",
    "nlp = nlpp.fillna(value='neutral')\n",
    "print(len(nlp))\n",
    "\n",
    "# Assuming df is your DataFrame and 'column_name' is the name of the column you want to check\n",
    "null_count = nlp['DEMEANOR_OF_PERSON_STOPPED'].isnull().sum()\n",
    "print(len(nlp))\n",
    "print(f\"Number of null values in 'column_name': {null_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataa = nlp['DEMEANOR_OF_PERSON_STOPPED'].tolist()\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "new_data = [ analyzer.polarity_scores(element)['compound'] for element in dataa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=[]\n",
    "for pair in data:\n",
    "    new.append(pair)\n",
    "# Create DataFrame from list of tuples\n",
    "final_df = pd.DataFrame(new, columns=['DEMEANOR_OF_PERSON_STOPPED', 'COMPOUND_SENTIMENT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_test=[\"FIREARM_FLAG\",\"FRISKED_FLAG\",\"SEARCHED_FLAG\"]\n",
    "\n",
    "Test1['FIREARM_FLAG'] = Test1['FIREARM_FLAG'].replace('(null)', 'No')\n",
    "Test1.replace('(null)', np.nan, inplace=True)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "Test1[\"SUSPECT_ARRESTED_FLAG\"] = lb.fit_transform(Test1[\"SUSPECT_ARRESTED_FLAG\"])\n",
    "Test1[\"FIREARM_FLAG\"] = lb.fit_transform(Test1[\"FIREARM_FLAG\"])\n",
    "Test1[\"FRISKED_FLAG\"] = lb.fit_transform(Test1[\"FRISKED_FLAG\"])\n",
    "Test1[\"SEARCHED_FLAG\"] = lb.fit_transform(Test1[\"SEARCHED_FLAG\"])\n",
    "\n",
    "\n",
    "Test1[\"SUSPECT_ARRESTED_FLAG\"].fillna(Test1[\"SUSPECT_ARRESTED_FLAG\"].median,inplace=True)\n",
    "Test1[\"FIREARM_FLAG\"].fillna(Test1[\"FIREARM_FLAG\"].median,inplace=True)\n",
    "Test1[\"FRISKED_FLAG\"].fillna(Test1[\"FRISKED_FLAG\"].median,inplace=True)\n",
    "Test1[\"SEARCHED_FLAG\"].fillna(Test1[\"SEARCHED_FLAG\"].median,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot-Encoding\n",
    "OneHot_Encode_feature = [\"STOP_WAS_INITIATED\",\"SUSPECTED_CRIME_DESCRIPTION\"]\n",
    "Label_En = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "Feature_Encoded = Label_En.fit_transform(Test1[OneHot_Encode_feature])\n",
    "Label_df = pd.DataFrame(Feature_Encoded.toarray(), columns=Label_En.get_feature_names_out(OneHot_Encode_feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding\n",
    "LE=LabelEncoder()\n",
    "Test1['SUSPECT_BODY_BUILD_TYPE']=LE.fit_transform(Test1[\"SUSPECT_BODY_BUILD_TYPE\"])\n",
    "Test1['SUSPECT_BODY_BUILD_TYPE'].fillna(Test1['SUSPECT_BODY_BUILD_TYPE'].mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming you have a list of texts in the 'DEMEANOR' feature\n",
    "# texts = Test1['DEMEANOR_OF_PERSON_STOPPED'].fillna('').tolist()\n",
    "\n",
    "# # Initialize the CountVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "\n",
    "# # Fit and transform the texts using the CountVectorizer\n",
    "# X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# # Get the feature names\n",
    "# feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# # Convert the vectorized data to a DataFrame\n",
    "# vectorized_data = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "\n",
    "# # Print the vectorized data\n",
    "# print(vectorized_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15102\n",
      "15102\n",
      "15102\n",
      "Number of null values in 'DEMEANOR_OF_PERSON_STOPPED': 0\n"
     ]
    }
   ],
   "source": [
    "nlpp = pd.read_excel(\"sqf2022.xlsx\", usecols=[\"DEMEANOR_OF_PERSON_STOPPED\"])\n",
    "print(len(nlpp))\n",
    "nlp = nlpp.fillna(value='neutral')\n",
    "print(len(nlp))\n",
    "\n",
    "# Assuming df is your DataFrame and 'column_name' is the name of the column you want to check\n",
    "null_count = nlp['DEMEANOR_OF_PERSON_STOPPED'].isnull().sum()\n",
    "print(len(nlp))\n",
    "print(f\"Number of null values in 'DEMEANOR_OF_PERSON_STOPPED': {null_count}\")\n",
    "data = nlp['DEMEANOR_OF_PERSON_STOPPED'].tolist()\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "new_data = [analyzer.polarity_scores(element)['compound'] for element in data]\n",
    "new = [(pair, compound) for pair, compound in zip(data, new_data)]\n",
    "# Create DataFrame from list of tuples\n",
    "final_df = pd.DataFrame(new, columns=['DEMEANOR_OF_PERSON_STOPPED', 'COMPOUND_SENTIMENT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Test1 = pd.concat([Test1, Label_df], axis=1)\n",
    "#Test1=pd.concat([Test1,vectorized_data],axis=1)\n",
    "Test1 = pd.concat([Test1, final_df], axis=1)\n",
    "\n",
    "#cat_feature=list(Label_df.columns)+Feature_test+list(vectorized_data.columns)\n",
    "cat_feature=list(Label_df.columns)+Feature_test+[\"COMPOUND_SENTIMENT\"]\n",
    "\n",
    "# drop the original categorical feature column\n",
    "Test1 = Test1.drop(columns=OneHot_Encode_feature)\n",
    "Test1= Test1.drop(columns=\"DEMEANOR_OF_PERSON_STOPPED\")\n",
    "\n",
    "Test1.to_csv('output.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data,test_data=train_test_split(Test1,test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "#classi\n",
    "X_train = train_data[cat_feature] # training features_for Random forest\n",
    "y_train = train_data['SUSPECT_ARRESTED_FLAG'] # training target variable for random forest\n",
    "\n",
    "X_test = test_data[cat_feature] # testing features\n",
    "y_test = test_data['SUSPECT_ARRESTED_FLAG'] # testing target variable\n",
    "\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_N=MultinomialNB()\n",
    "# Model_N.fit(X_train,y_train)\n",
    "# N_prediction=Model_N.predict(X_test)\n",
    "# train_N_prediction=Model_N.predict(X_train)\n",
    "# N_train_accuracy=accuracy_score(y_train,train_N_prediction)\n",
    "# N_accuracy=accuracy_score(y_test,N_prediction)\n",
    "\n",
    "# print('Train_Accuracy:', N_accuracy)\n",
    "# print('Accuracy:', N_train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_N_Over = MultinomialNB()\n",
    "# Model_N_Over.fit(X_train_oversampled, y_train_oversampled)\n",
    "# N_prediction_Over = Model_N_Over.predict(X_test)\n",
    "# train_N_prediction_Over = Model_N_Over.predict(X_train_oversampled)\n",
    "# N_train_accuracy_Over = accuracy_score(y_train_oversampled, train_N_prediction_Over)\n",
    "# N_accuracy_Over = accuracy_score(y_test, N_prediction_Over)\n",
    "\n",
    "# print('Train_Accuracy:', N_train_accuracy_Over)\n",
    "# print('Accuracy:', N_accuracy_Over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.888585382004801\n",
      "Accuracy: 0.8593181065872227\n"
     ]
    }
   ],
   "source": [
    "model_R = RandomForestClassifier(random_state=42)\n",
    "#model_R.fit(train_data[Feature_test], train_data[\"SUSPECT_ARRESTED_FLAG\"])\n",
    "\n",
    "#with only caterogical data but transform to numeric/ with both\n",
    "\n",
    "model_R.fit(X_train,y_train)\n",
    "Prediction=model_R.predict(X_test)\n",
    "\n",
    "train_Prediction =model_R.predict(X_train)\n",
    "\n",
    "\n",
    "train_accuracy=accuracy_score(y_train,train_Prediction)\n",
    "\n",
    "accuracy = accuracy_score(y_test, Prediction)\n",
    "\n",
    "\n",
    "print('Train_Accuracy:', train_accuracy)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.8811470333209463\n",
      "Accuracy: 0.8497186362131744\n"
     ]
    }
   ],
   "source": [
    "model_R_Over = RandomForestClassifier(random_state=42)\n",
    "#model_R.fit(train_data[Feature_test], train_data[\"SUSPECT_ARRESTED_FLAG\"])\n",
    "\n",
    "#with only caterogical data but transform to numeric/ with both\n",
    "\n",
    "model_R_Over.fit(X_train_oversampled,y_train_oversampled)\n",
    "Prediction_Over=model_R_Over.predict(X_test)\n",
    "\n",
    "train_Prediction_Over =model_R_Over.predict(X_train_oversampled)\n",
    "\n",
    "\n",
    "train_accuracy_Over=accuracy_score(y_train_oversampled,train_Prediction_Over)\n",
    "\n",
    "accuracy_Over = accuracy_score(y_test, Prediction_Over)\n",
    "\n",
    "\n",
    "print('Train_Accuracy:', train_accuracy_Over)\n",
    "print('Accuracy:', accuracy_Over)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RMSE: 0.34011043399243346\n",
      "Training RMSE: 0.3450124614237926\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing and training data, and calculate RMSE\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "\n",
    "print('Testing RMSE:', test_rmse)\n",
    "print('Training RMSE:', train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8656074147633234\n",
      "Train Accuract: 0.8627597053224071\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000,random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "log_predict=logreg.predict(X_test)\n",
    "log_score=accuracy_score(y_test,log_predict)\n",
    "\n",
    "train_log_predict=logreg.predict(X_train)\n",
    "train_log_score=accuracy_score(y_train,train_log_predict)\n",
    "\n",
    "print(\"Accuracy:\",log_score)\n",
    "print(\"Train Accuract:\",train_log_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8530287984111221\n",
      "Train Accuracy: 0.8381023163631859\n"
     ]
    }
   ],
   "source": [
    "logreg_Over = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_Over.fit(X_train_oversampled, y_train_oversampled)\n",
    "log_predict_Over = logreg_Over.predict(X_test)\n",
    "log_score_Over = accuracy_score(y_test, log_predict_Over)\n",
    "\n",
    "train_log_predict_Over = logreg_Over.predict(X_train_oversampled)\n",
    "train_log_score_Over = accuracy_score(y_train_oversampled, train_log_predict_Over)\n",
    "\n",
    "print(\"Accuracy:\", log_score_Over)\n",
    "print(\"Train Accuracy:\", train_log_score_Over)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score:  0.8563389606090699\n",
      "Train_Decision Tree score:  0.888585382004801\n"
     ]
    }
   ],
   "source": [
    "Dec_model=DecisionTreeClassifier(random_state=42)\n",
    "Dec_model.fit(X_train,y_train)\n",
    "Dec_predict=Dec_model.predict(X_test)\n",
    "Train_Dec_predict=Dec_model.predict(X_train)\n",
    "Dec_accuracy=accuracy_score(y_test,Dec_predict)\n",
    "Train_Dec_accuracy=accuracy_score(y_train,Train_Dec_predict)\n",
    "print(\"Decision Tree score: \",Dec_accuracy)\n",
    "print(\"Train_Decision Tree score: \",Train_Dec_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score on testing data:  0.8444223766964581\n",
      "Decision Tree score on training data (oversampled):  0.8811470333209463\n"
     ]
    }
   ],
   "source": [
    "Dec_model_Over = DecisionTreeClassifier(random_state=42)\n",
    "Dec_model_Over.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "Dec_predict_Over = Dec_model_Over.predict(X_test)\n",
    "\n",
    "# Make predictions on the training data (oversampled)\n",
    "Train_Dec_predict_Over = Dec_model_Over.predict(X_train_oversampled)\n",
    "\n",
    "# Calculate accuracy scores\n",
    "Dec_accuracy_Over = accuracy_score(y_test, Dec_predict_Over)\n",
    "Train_Dec_accuracy_Over = accuracy_score(y_train_oversampled, Train_Dec_predict_Over)\n",
    "\n",
    "print(\"Decision Tree score on testing data: \", Dec_accuracy_Over)\n",
    "print(\"Decision Tree score on training data (oversampled): \", Train_Dec_accuracy_Over)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error 0.6765971532605097\n",
      "TestError: 0.6682393841569406\n"
     ]
    }
   ],
   "source": [
    "dummy_class = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_class.fit(X_train,y_train)\n",
    "y_predict=dummy_class.predict(X_test)\n",
    "y_train_predict=dummy_class.predict(X_train)\n",
    "Dummy_accuracy = accuracy_score(y_test, y_predict)\n",
    "Dummy_train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "print(\"Training error\",Dummy_accuracy)\n",
    "print(\"TestError:\", Dummy_train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7871565706719629\n"
     ]
    }
   ],
   "source": [
    "Dec_model_OneR=DecisionTreeClassifier(random_state=42,max_depth=1)\n",
    "Dec_model_OneR.fit(train_data[\"SEARCHED_FLAG\"].values.reshape(-1, 1), train_data[\"SUSPECT_ARRESTED_FLAG\"])\n",
    "predictions = Dec_model_OneR.predict(test_data[\"SEARCHED_FLAG\"].values.reshape(-1, 1))\n",
    "accuracy_OneR = accuracy_score(test_data[\"SUSPECT_ARRESTED_FLAG\"], predictions)\n",
    "print(\"Accuracy:\", accuracy_OneR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier 0.8619662363455809\n"
     ]
    }
   ],
   "source": [
    "estimators=[(\"logreg\", logreg), (\"rf\", model_R), (\"Dc\", Dec_model)]#,(\"Naive\",Model_N)]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators)\n",
    "ensemble.fit(X_train, y_train)\n",
    "#test our model on the test data\n",
    "print(\"Voting Classifier\",ensemble.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient  0.8695796094008607\n",
      "Train Gradient  0.8670639847694728\n"
     ]
    }
   ],
   "source": [
    "G_Model=GradientBoostingClassifier(random_state=42) #look for the base alg !! Gradient Boosted Decision Trees?\n",
    "G_Model.fit(X_train,y_train)\n",
    "G_predict=G_Model.predict(X_test)\n",
    "G_predict_train=G_Model.predict(X_train)\n",
    "G_accracy=accuracy_score(y_test,G_predict)\n",
    "G_accracy_train=accuracy_score(y_train,G_predict_train)\n",
    "print(\"Gradient \", G_accracy)\n",
    "print(\"Train Gradient \", G_accracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient  0.8563389606090699\n",
      "Train Gradient  0.8457203022420414\n"
     ]
    }
   ],
   "source": [
    "G_Model=GradientBoostingClassifier(random_state=42) #look for the base alg !! Gradient Boosted Decision Trees?\n",
    "G_Model.fit(X_train_oversampled,y_train_oversampled)\n",
    "G_predict=G_Model.predict(X_test)\n",
    "G_predict_train=G_Model.predict(X_train_oversampled)\n",
    "G_accracy=accuracy_score(y_test,G_predict)\n",
    "G_accracy_train=accuracy_score(y_train_oversampled,G_predict_train)\n",
    "print(\"Gradient \", G_accracy)\n",
    "print(\"Train Gradient \", G_accracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.8523305874229724 \n",
      " \n",
      "\n",
      "RandomForestClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.8523305874229724 \n",
      " \n",
      "\n",
      "LogisticRegression(max_iter=1000, random_state=0) \n",
      "\n",
      "Cross-Validation Accuracy: 0.8616010488619519 \n",
      " \n",
      "\n",
      "DecisionTreeClassifier(random_state=42) \n",
      "\n",
      "Cross-Validation Accuracy: 0.8516679932706245 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [RandomForestClassifier(random_state=42),RandomForestClassifier(random_state=42),\n",
    "            LogisticRegression(random_state=0,max_iter=1000),DecisionTreeClassifier(random_state=42)#,MultinomialNB()\n",
    "         ]\n",
    "for model in models:\n",
    "    print(model, '\\n')\n",
    "    score = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=5).mean()\n",
    "    print('Cross-Validation Accuracy:', score, '\\n', '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
