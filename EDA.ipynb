{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values: 1685\n",
      "Unique values: ['FLED ON FOOT' nan 'NERVOUS CHANGING DIRECTION FROM OFFICERS RUNNING' ...\n",
      " 'IRRITATED CONFUSED' 'AGITATED AND THEN CALM' 'ANNOYED NON COMPLIANT']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#ssss\n",
    "Table1_target = [\"SUSPECT_ARRESTED_FLAG\", \"STOP_WAS_INITIATED\",\n",
    "                 \"OBSERVED_DURATION_MINUTES\", \"SUSPECTED_CRIME_DESCRIPTION\",\n",
    "                 \"STOP_DURATION_MINUTES\", \"FIREARM_FLAG\",\n",
    "                 \"SUSPECT_RACE_DESCRIPTION\",\n",
    "                 \"DEMEANOR_OF_PERSON_STOPPED\", \"SUSPECT_BODY_BUILD_TYPE\"]\n",
    "\n",
    "\n",
    "\n",
    "Table1 = pd.read_excel(\"sqf2022.xlsx\", usecols=Table1_target)\n",
    "\n",
    "#replace (null) in fire arm flag with No, so it wouldn't cause problem if we want to remove \n",
    "# (null) that represent missing value\n",
    "Table1['FIREARM_FLAG'] = Table1['FIREARM_FLAG'].replace('(null)', 'No')\n",
    "\n",
    "n_unique = Table1['DEMEANOR_OF_PERSON_STOPPED'].nunique()\n",
    "unique_values = Table1['DEMEANOR_OF_PERSON_STOPPED'].unique()\n",
    "print(f'Number of unique values: {n_unique}')\n",
    "print(f'Unique values: {unique_values}')\n",
    "\n",
    "\n",
    "#Binarize\n",
    "lb = LabelBinarizer()\n",
    "Table1[\"SUSPECT_ARRESTED_FLAG\"] = lb.fit_transform(Table1[\"SUSPECT_ARRESTED_FLAG\"])\n",
    "Table1[\"FIREARM_FLAG\"] = lb.fit_transform(Table1[\"FIREARM_FLAG\"])\n",
    "\n",
    "#Bag-of-word Incomplete!\n",
    "Table1[\"DEMEANOR_OF_PERSON_STOPPED\"].fillna(\"Calm\", inplace=True)\n",
    "vectorizer = CountVectorizer()\n",
    "BOW_trans = vectorizer.fit_transform(Table1[\"DEMEANOR_OF_PERSON_STOPPED\"])\n",
    "BOW_df = pd.DataFrame(BOW_trans.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "#Lable encodeing\n",
    "Label_Encode_feature = [\"SUSPECT_RACE_DESCRIPTION\",\"SUSPECTED_CRIME_DESCRIPTION\",\"STOP_WAS_INITIATED\"]\n",
    "Label_En = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "Feature_Encoded = Label_En.fit_transform(Table1[Label_Encode_feature])\n",
    "Label_df = pd.DataFrame(Feature_Encoded.toarray(), columns=Label_En.get_feature_names_out(Label_Encode_feature))\n",
    "#Labeled_columns = Label_En.get_feature_names(Label_Encode_feature)\n",
    "\n",
    "# join the one-hot encoded columns to the original dataframe\n",
    "#Table1 = Table1.join(Label_df,BOW_df)\n",
    "Table1 = pd.concat([Table1, Label_df], axis=1)\n",
    "\n",
    "# drop the original categorical feature column\n",
    "Table1 = Table1.drop(columns=Label_Encode_feature)\n",
    "#Table1 = Table1.drop(columns=\"DEMEANOR_OF_PERSON_STOPPED\")\n",
    "# print the updated dataframe\n",
    "\n",
    "\n",
    "\n",
    "# save the updated dataframe to a CSV file\n",
    "Table1.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
